{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250ba2d4",
   "metadata": {},
   "source": [
    "# 📝 KNN (K-Nearest Neighbors) – Exam Notes\n",
    "🔹 Definition: \n",
    "Supervised ML algorithm (Classification + Regression).\n",
    "Predicts label/value of a new point by looking at its K nearest neighbors.\n",
    "Lazy learner → no training phase, only prediction time work.\n",
    "- 🔹 Steps of KNN\n",
    "Choose K (odd number preferred).\n",
    "Calculate distance between new point & training data.\n",
    "Euclidean: \n",
    "∑\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    "−\n",
    "𝑦\n",
    "𝑖\n",
    ")\n",
    "2\n",
    "∑(x\n",
    "i\t​\n",
    "−y\n",
    "i\t​\n",
    "\n",
    ")\n",
    "2\n",
    "- \n",
    "Manhattan: \n",
    "∑\n",
    "∣\n",
    "𝑥\n",
    "𝑖\n",
    "−\n",
    "𝑦\n",
    "𝑖\n",
    "∣\n",
    "∑∣x\n",
    "i\t​\n",
    "−y\n",
    "i\n",
    "∣\n",
    "- \n",
    "Cosine similarity (for text/angles)\n",
    "\n",
    "Select K nearest neighbors.\n",
    "\n",
    "Prediction:\n",
    "\n",
    "Classification → majority vote\n",
    "\n",
    "Regression → average value\n",
    "\n",
    "- 🔹 When to Use?\n",
    "\n",
    "- Dataset output (Y) categorical → Classification\n",
    "- Dataset output (Y) continuous/numerical → Regression\n",
    "## 🔹 Advantages\": \n",
    "- ✅ Simple & intuitive\n",
    "- ✅ No training cost (fast to set up)\n",
    "- ✅ Works with non-linear decision boundaries\n",
    "- ✅ Handles multi-class problems\n",
    "## 🔹 Disadvantages\n",
    "- ❌ Prediction slow (distance calc for every test point)\n",
    "- ❌ Memory hungry (stores all training data)\n",
    "- ❌ Sensitive to irrelevant features & scaling\n",
    "- ❌ High dimensions → distance becomes meaningless (curse of dimensionality)\n",
    "# 🔹 Important Points\n",
    "- always normalize/standardize features before KNN.\n",
    "- Best K chosen using cross-validation.\n",
    "- Small K → noisy results, large K → smoother but may ignore local patterns.\n",
    "### 🔹 Shortcut Memory Trick\" :\n",
    "1. 👉 KNN = “Look at your K closest neighbors, follow majority (classification) or average (regression).”\n",
    "2. ⚡ Bas ye points yaad rakh lo → exam me koi bhi question (definition, working, pros/cons, example) easily tackle kar logi.\n",
    "3. Chaho main tumhe ek 1-page mindmap/diagram bana ke dikhau (distance + voting + pros/cons ek jagah pe)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c89a5a",
   "metadata": {},
   "source": [
    "# 🟢 Euclidean Distance Kya Hai?\n",
    "\n",
    "Euclidean distance asal mein 2 points ke beech ki straight-line (direct) distance hoti hai — jaise tum ruler se naap lo 📏.\n",
    "\n",
    "📌 Formula (2D case):\n",
    "\n",
    "Agar tumhare paas do points hain:\n",
    "\n",
    "Point A = (x₁, y₁)\n",
    "\n",
    "Point B = (x₂, y₂)\n",
    "\n",
    "To unka distance hoga:\n",
    "𝑑\n",
    "=\n",
    "(\n",
    "𝑥\n",
    "2\n",
    "−\n",
    "𝑥\n",
    "1\n",
    ")\n",
    "2\n",
    "+\n",
    "(\n",
    "𝑦\n",
    "2\n",
    "−\n",
    "𝑦\n",
    "1\n",
    ")\n",
    "2\n",
    "d=\n",
    "(x\n",
    "2\n",
    "−x\n",
    "1\t​\n",
    ")\n",
    "2\n",
    "+(y\n",
    "2\t​\n",
    "−y\n",
    "1\n",
    ")\n",
    "2\n",
    "- 📌 Formula (n-dimensional case):\n",
    "\n",
    "Agar features zyada hain (weight, color, sweetness, size, …), aur tumhare paas n features hain:\n",
    "𝑑\n",
    "=\n",
    "∑\n",
    "𝑖\n",
    "=\n",
    "1\n",
    "𝑛\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    "−\n",
    "𝑦\n",
    "𝑖\n",
    ")\n",
    "2\n",
    "d=\n",
    "i=1\n",
    "∑\n",
    "n\n",
    "(x\n",
    "i\n",
    "−y\n",
    "i\n",
    ")\n",
    "2\n",
    "Matlab → har feature ka difference square karo, sab differences jod do, aur uska square root le lo.\n",
    "- 🟢 Example:\n",
    "Socho tumhare paas fruits dataset hai:\n",
    "\n",
    "Apple = (weight = 150g, color = 8)\n",
    "\n",
    "Orange = (weight = 200g, color = 6)\n",
    "\n",
    "New fruit = (weight = 180g, color = 7)\n",
    "\n",
    "Distance from Apple:\n",
    "\n",
    "(\n",
    "180\n",
    "−\n",
    "150\n",
    ")\n",
    "2\n",
    "+\n",
    "(\n",
    "7\n",
    "−\n",
    "8\n",
    ")\n",
    "2\n",
    "=\n",
    "900\n",
    "+\n",
    "1\n",
    "≈\n",
    "30.01\n",
    "(180−150)\n",
    "2\n",
    "+(7−8)\n",
    "2\n",
    "=\n",
    "900+1\n",
    "≈30.01\n",
    "Distance from Orange:\n",
    "\n",
    "(\n",
    "180\n",
    "−\n",
    "200\n",
    ")\n",
    "2\n",
    "+\n",
    "(\n",
    "7\n",
    "−\n",
    "6\n",
    ")\n",
    "2\n",
    "=\n",
    "400\n",
    "+\n",
    "1\n",
    "≈\n",
    "20.02\n",
    "(180−200)\n",
    "2\n",
    "+(7−6)\n",
    "2\n",
    "=\n",
    "400+1\n",
    "≈20.02\n",
    "👉 Kyunki 20 < 30, naya fruit Orange ke zyada close hai → KNN bolega ye Orange hai 🍊\n",
    "- 🟢 How it Works in KNN\n",
    "Naya data point aaya\n",
    "Uska distance calculate karo sab training points se\n",
    "Jo nearest k points honge, unko dekho\n",
    "Majority vote (classification) ya average (regression) le lo\n",
    "- ⚡ Short-cut socho:\n",
    "\"Euclidean distance = straight-line distance in feature space\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7deb746",
   "metadata": {},
   "source": [
    "# 📘 Manhattan Distance (L1 Norm)\n",
    "🔹 Definition\n",
    "Manhattan Distance (Taxicab Distance / L1 Norm) is the sum of absolute differences between the coordinates of two points.\n",
    "1. \n",
    "Isko \"Manhattan\" is liye kehte hain kyunki ek taxi driver New York ki grid wali streets se travel karta hai → seedha left/right, upar/neeche, diagonal nahi 🚖🗽.\n",
    "🔹 Formula\n",
    "For two points \n",
    "- 𝑃(𝑥1,𝑦1)P(x1,y1) and 𝑄(𝑥2,𝑦2)Q(x2,y2):𝐷=∣𝑥2−𝑥1∣+∣𝑦2−𝑦1∣D=∣x2−x1∣+∣y2−y1∣\n",
    "General (n-dimensions):\n",
    "𝐷=∑𝑖=1𝑛∣𝑥𝑖−𝑦𝑖∣D=i=1∑n∣xi−yi\t\n",
    "🔹 Example\n",
    "- Point A = (2, 3), Point B = (5, 7)\n",
    "𝐷=∣5−2∣+∣7−3∣=3+4=7\n",
    "D=∣5−2∣+∣7−3∣=3+4=7\n",
    "- \n",
    "👉 Euclidean distance yahan 5 hota, Manhattan 7 nikla.\n",
    "- 🔹 Applications\n",
    "1. Text mining / NLP → word frequency differences\n",
    "2. High-dimensional / sparse data (e.g. TF-IDF, images)\n",
    "3. Grid-based movement problems (pathfinding in games, robotics)\n",
    "4. Sometimes used in KNN, clustering\n",
    "- 🔹 Advantages : \n",
    "1. ✅ Simple to compute\n",
    "2. ✅ Works well with high-dimensional sparse data\n",
    "3. ✅ Better when movement is restricted to grid\n",
    "- 🔹 Disadvantages\n",
    "- ❌ Less intuitive than Euclidean for continuous geometric data\n",
    "- ❌ Can give larger distances than Euclidean (less compact)\n",
    "- ❌ Sensitive to feature scaling\n",
    "- 🔹 When to Use?\n",
    "1. Use Euclidean → when similarity is geometric/continuous (height, weight, size)\n",
    "2. Use Manhattan → when features are discrete, sparse, or grid-like (text data, pixel intensity, pathfinding)\n",
    "#### ⚡ Shortcut to Remember:\n",
    "- “Seedhi galiyon wali taxi → Manhattan distance” "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a585d88",
   "metadata": {},
   "source": [
    "# 📘 Minkowski Distance\n",
    "🔹 Definition: \n",
    "Minkowski distance is a generalized distance metric jo Manhattan (L1) aur Euclidean (L2) dono ko cover karta hai depending on the parameter p.\n",
    "It defines distance between two points in an n-dimensional space.\n",
    "🔹 Formula\n",
    "For two points \n",
    "𝑃(𝑥1,𝑥2,...,𝑥𝑛)P(x1,x2,...,xn) and 𝑄(𝑦1,𝑦2,...,𝑦𝑛)Q(y1,y2,...,yn):𝐷=(∑𝑖=1𝑛∣𝑥𝑖−𝑦𝑖𝑝)1𝑝D(i=1∑n\t∣xi−yi∣p)p1\n",
    "🔹 Special Cases\n",
    "If \n",
    "𝑝=1p=1 → Manhattan Distance\n",
    "𝐷=∑∣𝑥𝑖−𝑦𝑖∣D=∑∣xi−yi∣\n",
    "If \n",
    "𝑝=2p=2 → Euclidean Distance\n",
    "𝐷=∑(𝑥𝑖−𝑦𝑖)2D=∑(xi−yi)2\t\n",
    "If \n",
    "𝑝→∞p→∞ → Chebyshev Distance\n",
    "𝐷=max(∣𝑥𝑖−𝑦𝑖∣)D=max(∣xi−yi∣)\n",
    "🔹 Example\n",
    "Let’s say points: \n",
    "𝐴(2,3)\n",
    "A(2,3), 𝐵(5,7)B(5,7)\n",
    "For p=1 (Manhattan):\n",
    "\n",
    "∣5−2∣+∣7−3∣=7\n",
    "∣5−2∣+∣7−3∣=7\n",
    "For p=2 (Euclidean):\n",
    "(5−2)2+(7−3)2=25=5(5−2)2+(7−3)2​=25=5\n",
    "For p=3 (Minkowski general):\n",
    "\n",
    "(∣5−2∣3+∣7−3∣3)1/3=(27+64)1/3=911/3≈4.49\n",
    "(∣5−2∣3+∣7−3∣3)1/3=(27+64)1/3=911/3≈4.49\n",
    "🔹 Applications\n",
    "\n",
    "KNN classifier (choosing distance metric)\n",
    "1. Clustering algorithms (K-means, Hierarchical clustering)\n",
    "2. Any ML/AI task where \"distance\" matters but you want flexibility\n",
    "\n",
    "🔹 Advantages\n",
    "1. ✅ Flexible (covers multiple distances in one formula)\n",
    "2. ✅ You can tune p based on your dataset\n",
    "3. ✅ Makes it easy to experiment with metrics\n",
    "\n",
    "🔹 Disadvantages\n",
    "\n",
    "1. ❌ Requires choosing the right p (trial & error)\n",
    "2. ❌ Sensitive to feature scaling (needs normalization)\n",
    "3. ❌ For high dimensions, can become computationally expensive\n",
    "\n",
    "⚡ Shortcut to Remember:\n",
    "👉 \"Minkowski = Distance ka Swiss Knife 🗡️ … Manhattan aur Euclidean dono uske special cases hain.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd04dea",
   "metadata": {},
   "source": [
    "# 📌 Hamming Distance (HD)\n",
    "✅ Definition:\n",
    "\n",
    "Measures the number of positions where two strings of equal length differ.\n",
    "\n",
    "✅ Formula:\n",
    "𝐻𝐷(𝑥,𝑦)=∑(𝑥𝑖≠𝑦𝑖)HD(x,y)=∑(xi=yi)\n",
    "\n",
    "(Count mismatches only)\n",
    "\n",
    "✅ Example:\n",
    "x = 1011101  \n",
    "y = 1001001  \n",
    "HD = 2\n",
    "\n",
    "✅ When to Use:\n",
    "- Binary / categorical / string data\n",
    "- Error detection in communication\n",
    "- DNA sequencing (genomics)\n",
    "- Text comparison (spell check, plagiarism)\n",
    "- ✅ Key Point:\n",
    "- Works only if lengths are same.\n",
    "- Euclidean/Manhattan = numeric data\n",
    "- Hamming = categorical/string data\n",
    "⚡ Shortcut:\n",
    "👉 Hamming = \"Count the mismatches.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
